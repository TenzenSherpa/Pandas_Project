{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc515c4f-fa07-47aa-af30-ee8708a100f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be02b1e-0c2a-4d49-be2c-8e3543080427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version, 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas version,\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6fa0e-37d2-4194-a946-fa2ab965a6be",
   "metadata": {},
   "source": [
    "Pandas introduces two primary data structures: Series and DataFrame, along\n",
    "with an Index that labels the data.\n",
    "Series: Its a one-dimensional array of data with an index (like a labeled column of values).\n",
    "DataFrame: DataFrame is a two-dimensional table of data, consisting of multiple Series \n",
    "that share the same index (like a spreadsheet or SQL table)\n",
    "The index is a set of labels for each row (and each column, in the case of column names),\n",
    "by default, Pandas assigns an integer index starting form 0 for rach row.\n",
    "Why do we use pandas?\n",
    "In real-world data analysis, you will often actually work with dataset\n",
    "(csv files, databases, JSON APIS, etc). That would need cleaning, transformation and summarization.\n",
    "Pandas provides high-level data structure and functions that makes theses tasks easy,\n",
    "Its built on Numpy, and it gives high performace of numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb91356-bc88-4e4b-959c-9671319e12d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series of Scores:\n",
      "Alice      89\n",
      "Bob        90\n",
      "Charlie    88\n",
      "Dana       88\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Series of exam scores\n",
    "scores = pd.Series([89, 90, 88, 88], index=[\"Alice\", \"Bob\", \"Charlie\", \"Dana\"])\n",
    "print(\"Series of Scores:\")\n",
    "print(scores, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d949d628-353e-4ae5-8127-20a291acd575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age City  Score\n",
      "0    Alice   45   NY     89\n",
      "1      Bob   33   LA     90\n",
      "2  Charlie   55   NY     88\n",
      "3     Dana   22   TX     88\n"
     ]
    }
   ],
   "source": [
    "# Create a Dataframe of students with multiple columns\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Dana\"],\n",
    "    \"Age\": [45, 33, 55, 22],\n",
    "    \"City\": [\"NY\", \"LA\", \"NY\", \"TX\"],\n",
    "    \"Score\": [89, 90, 88, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6f9551-3b51-4cae-8ebd-a48c9f91754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of df: Index(['Name', 'Age', 'City', 'Score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns of df:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c574f5-ec2c-4b9e-8e9a-6bd833f3311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame read from CSV:\n",
      "      Name  Age City\n",
      "0    Alice   45   NY\n",
      "1      Bob   33   LA\n",
      "2  Charlie   55   NY\n",
      "3     Dana   22   TX \n",
      "\n",
      "DataFrame has been written to the file\n"
     ]
    }
   ],
   "source": [
    "# Creating csv data (comma seperated values)\n",
    "csv_data = \"\"\"Name,Age,City\n",
    "Alice,45,NY\n",
    "Bob,33,LA\n",
    "Charlie,55,NY\n",
    "Dana,22,TX\n",
    "\"\"\"\n",
    "# Use StringIo to simulate a file object from the string (for demo purposes)\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "print(\"DataFrame read from CSV:\")\n",
    "print(df,\"\\n\")\n",
    "\n",
    "# Now write this DataFrame to an Excel file (this will actually create an actual file\n",
    "df.to_excel(\"people.xlsx\", index=False) # index=False to omits the index in the file\n",
    "\n",
    "print(\"DataFrame has been written to the file\")\n",
    "\n",
    "# In the code above pd.read_csv was used to parse CSV data in practice, you would\n",
    "# pd.read_csv(\"path/to/your/file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ec41c8-c2f9-4dbe-8f48-ad43d5d1d3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame read from JSON:\n",
      "  Name  Score\n",
      "0    X      5\n",
      "1    Y      7\n",
      "DataFrame has been written to 'sample.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Creep\\AppData\\Local\\Temp\\ipykernel_16644\\1638509791.py:3: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_json = pd.read_json(json_data)\n"
     ]
    }
   ],
   "source": [
    "# JSON string example\n",
    "json_data = '[{\"Name\": \"X\", \"Score\":5}, {\"Name\": \"Y\", \"Score\": 7}]'\n",
    "df_json = pd.read_json(json_data)\n",
    "print(\"DataFrame read from JSON:\")\n",
    "print(df_json)\n",
    "\n",
    "# Write DataFrame to JSON File\n",
    "df_json.to_json(\"Sample.json\", orient=\"records\")\n",
    "print(\"DataFrame has been written to 'sample.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47f69a1-e165-4476-bca1-96a6c2ffec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product  Price  Quantity\n",
      "0  Widget     23        33\n",
      "1  Gadget     34        44\n",
      "Dataframe has been written to products.csv\n"
     ]
    }
   ],
   "source": [
    "product_data = {\n",
    "    \"Product\": [\"Widget\", \"Gadget\"],\n",
    "    \"Price\": [23,34],\n",
    "    \"Quantity\": [33,44]\n",
    "}\n",
    "df = pd.DataFrame(product_data)\n",
    "print(df)\n",
    "# Write DataFrame to csv file\n",
    "df.to_csv(\"products.csv\", index=False)\n",
    "print(\"Dataframe has been written to products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7153bfc9-a6a3-46bc-9a27-809047f994f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product  Price  Quantity\n",
      "0  Widget     23        33\n",
      "1  Gadget     34        44\n"
     ]
    }
   ],
   "source": [
    "# Reading from the csv file\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfaaddc1-a58c-49ae-970d-1d3fa19ad913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age City\n",
      "0    Alice   45   NY\n",
      "1      Bob   33   LA\n",
      "2  Charlie   55   NY\n",
      "3     Dana   22   TX\n"
     ]
    }
   ],
   "source": [
    "# Reading from the excel file\n",
    "df = pd.read_excel(\"people.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f18042-7575-4beb-8da8-f8ddc9d3e19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Score\n",
      "0    X      5\n",
      "1    Y      7\n"
     ]
    }
   ],
   "source": [
    "# Reading from the JSON file\n",
    "df = pd.read_json(\"Sample.json\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a687ba-e47a-4359-8a3e-bf31301728c5",
   "metadata": {},
   "source": [
    "Once data is loaded into a DataFrame, the first step is to inspect it.\n",
    "Its shape, structure and basic statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee5f91-f278-45c3-abb3-bff2e8833192",
   "metadata": {},
   "source": [
    "# This if for DataFrame\n",
    "df.head(n) - view the first n rows (default is 5)\n",
    "df.tail(n) - view the last n rows\n",
    "df.shape - get the number of rows and colums as tuple (n_rows, n_cols)\n",
    "df.columns - get the column labels\n",
    "df.index - get the index (row labels)\n",
    "df.dtypes - data types of each column\n",
    "df.info() - concise summary: shows the index range, column names,\n",
    "            non-null counts, and dtypes.\n",
    "df.describe() - descriptive statics for numeric columns\n",
    "                (count, mean, std, min, quartiles, max)\n",
    "if we pass include='all', it will attempt to summarize non-numerical columns.\n",
    "(example count of unique, top value frequency)\n",
    "\n",
    "# Series\n",
    "ser.value_counts() - frequency count of unique values\n",
    "ser.unique() - array of unique values\n",
    "ser.mean(), ser.min(), ser.max(), ser.sum(), ser.median() - common statistics\n",
    "ser.isna() - Boolean series indicating missing values (Nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee452bee-4e53-44a0-81be-e4ccdbf47f2a",
   "metadata": {},
   "source": [
    "Whenever you get a new dataset, you should always perform an initial exploration.\n",
    "For example, if you're analyzing a dataset of customer purchases-\n",
    "How many records are there?\n",
    "What columns(features) does it have?\n",
    "Are they numeric, catagorical, dates?\n",
    "Are there missing values to worry about?\n",
    "What are the ranges of typical values of numerical values (describe())?\n",
    "Do any columns have suspecious values (like negative values, or ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48bb473-4b57-4db4-a7dc-887fa9477d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows:\n",
      "       Name  Age City  Score\n",
      "0    Alice   45   NY     89\n",
      "1      Bob   33   LA     90\n",
      "2  Charlie   55   NY     88 \n",
      "\n",
      "DataFrame Shape (4, 4)\n",
      "Colums: Index(['Name', 'Age', 'City', 'Score'], dtype='object')\n",
      "Data Types:\n",
      " Name     object\n",
      "Age       int64\n",
      "City     object\n",
      "Score     int64\n",
      "dtype: object \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    4 non-null      object\n",
      " 1   Age     4 non-null      int64 \n",
      " 2   City    4 non-null      object\n",
      " 3   Score   4 non-null      int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 260.0+ bytes\n",
      "\n",
      "Summary Statistics\n",
      "              Age      Score\n",
      "count   4.000000   4.000000\n",
      "mean   38.750000  88.750000\n",
      "std    14.338177   0.957427\n",
      "min    22.000000  88.000000\n",
      "25%    30.250000  88.000000\n",
      "50%    39.000000  88.500000\n",
      "75%    47.500000  89.250000\n",
      "max    55.000000  90.000000\n",
      "0    NY\n",
      "1    LA\n",
      "2    NY\n",
      "3    TX\n",
      "Name: City, dtype: object\n",
      "Unique Cities: ['NY' 'LA' 'TX']\n",
      "Counts Of Each City:\n",
      " City\n",
      "NY    2\n",
      "LA    1\n",
      "TX    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code Demo\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Dana\"],\n",
    "    \"Age\": [45, 33, 55, 22],\n",
    "    \"City\": [\"NY\", \"LA\", \"NY\", \"TX\"],\n",
    "    \"Score\": [89, 90, 88, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"First 3 rows:\\n\", df.head(3),\"\\n\")\n",
    "print(\"DataFrame Shape\", df.shape)\n",
    "print(\"Colums:\", df.columns)\n",
    "print(\"Data Types:\\n\", df.dtypes,\"\\n\")\n",
    "df.info() # Prints into to console\n",
    "print(\"\\nSummary Statistics\\n\", df.describe())\n",
    "print(df[\"City\"])\n",
    "print(\"Unique Cities:\", df[\"City\"].unique())\n",
    "print(\"Counts Of Each City:\\n\", df[\"City\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47484ca2-9097-4368-9688-15978b30c932",
   "metadata": {},
   "source": [
    "# Indexing, Selecting, Filtering, and Sorting Data\n",
    "\n",
    "Pandas actually offers multiple ways to index and select.\n",
    "Column Selection, you can select a column as a series using df[\"ColumnName\"].\n",
    "To select multiple columns, you can pass a list: df[[\"ColA\", \"ColB\"]]\n",
    "It returns a new DataFrame with only those columns.\n",
    "\n",
    "Row selection:\n",
    "Using the .loc indexer. For df.loc[0] returns the row with index label 0\n",
    "If your DataFrame has a custom index [say, one of the columns as a index], you use label .loc\n",
    "allows you to select by row label and column label: df.loc[row_label, col_label]\n",
    "I can take slices as well (example, df.loc[2:4] for labels 2 through 4, inclusive).\n",
    "\n",
    "Row selection by position: \n",
    "Using the .iloc indexer, example, df.iloc[0] returns the first row (regardless of index).\n",
    "df.iloc[0:3] returns first three row (0,1,2). You can also do df.iloc[[0,2],[1,3]] to get\n",
    "specific rows and columns by integer position.\n",
    "\n",
    "Boolean indexing (Filtering):\n",
    "You can pass a boolean condition to the DataFrame to filter rows. For example: df[df[\"Age\"] > 30]\n",
    "returns only the rows where the Age columns is greater than 30.\n",
    "You can also combine conditions with & (and) and | (or)\n",
    "Example, df[(df[\"City\"] == \"NY\") & (df[df[\"Score\"] > 80]) gives me rows where city is NY and \n",
    "score > 80\n",
    "\n",
    "Sorting:\n",
    "Use df.sort_values(\"ColumnsName\") to sort by a columns (ascending by default)\n",
    "df.sort_values(\"ColumnName\", ascending = False) for descending.\n",
    "\n",
    "You can sort by multiple columns df.sort_values([\"City\", \"Age\"]) sort by City, then by age within \n",
    "each city. To sort by the index, use df.sort_index()\n",
    "\n",
    "Important things to know.\n",
    "Pandas indexing can be little confusing at first because of the dual use of []. \n",
    "Writing df[<conditions>] is shorthand for filtering rows by a condition (boolean indexing) while df[\"Col\"]\n",
    "selects a column. To avoid the ambiguity and pitfalls, It's ofter clearer to use .loc and .iloc\n",
    "for explicit indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b60b177d-6910-4494-9e8c-a8d09951d286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Name      5 non-null      object        \n",
      " 1   Dept      5 non-null      object        \n",
      " 2   Salary    5 non-null      int64         \n",
      " 3   HireDate  5 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(2)\n",
      "memory usage: 292.0+ bytes\n",
      "DataFrame: \n",
      "       Name       Dept  Salary   HireDate\n",
      "0    Alice         HR   60000 2019-05-01\n",
      "1      Bob         IT   75000 2021-07-15\n",
      "2  Charlie    Finance   80000 2020-09-30\n",
      "3    David         IT   70000 2022-01-10\n",
      "4      Eve  Marketing   65000 2018-03-20\n",
      "Name Series:\n",
      " 0      Alice\n",
      "1        Bob\n",
      "2    Charlie\n",
      "3      David\n",
      "4        Eve\n",
      "Name: Name, dtype: object \n",
      "\n",
      "Subset of DataFrame [Name and Salary:\n",
      "       Name  Salary\n",
      "0    Alice   60000\n",
      "1      Bob   75000\n",
      "2  Charlie   80000\n",
      "3    David   70000\n",
      "4      Eve   65000 \n",
      "\n",
      "First row using iloc:\n",
      " Name                      Alice\n",
      "Dept                         HR\n",
      "Salary                    60000\n",
      "HireDate    2019-05-01 00:00:00\n",
      "Name: 0, dtype: object \n",
      "\n",
      "Row with index label 2 using loc:\n",
      " Name                    Charlie\n",
      "Dept                    Finance\n",
      "Salary                    80000\n",
      "HireDate    2020-09-30 00:00:00\n",
      "Name: 2, dtype: object \n",
      "\n",
      "Employees with Salary > 70000:\n",
      "       Name     Dept  Salary   HireDate\n",
      "1      Bob       IT   75000 2021-07-15\n",
      "2  Charlie  Finance   80000 2020-09-30 \n",
      "\n",
      "Employees in IT Dept:\n",
      "     Name Dept  Salary   HireDate\n",
      "1    Bob   IT   75000 2021-07-15\n",
      "3  David   IT   70000 2022-01-10 \n",
      "\n",
      "IT employees with salary greater than 75000:\n",
      " Empty DataFrame\n",
      "Columns: [Name, Dept, Salary, HireDate]\n",
      "Index: [] \n",
      "\n",
      "Employees sorted by Salary (desc):\n",
      "       Name       Dept  Salary   HireDate\n",
      "2  Charlie    Finance   80000 2020-09-30\n",
      "1      Bob         IT   75000 2021-07-15\n",
      "3    David         IT   70000 2022-01-10\n",
      "4      Eve  Marketing   65000 2018-03-20\n",
      "0    Alice         HR   60000 2019-05-01 \n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: Salary, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"Dept\": [\"HR\", \"IT\", \"Finance\", \"IT\", \"Marketing\"],\n",
    "    \"Salary\": [60000, 75000, 80000, 70000, 65000],\n",
    "    \"HireDate\": pd.to_datetime([\"2019-05-01\", \"2021-07-15\", \"2020-09-30\", \"2022-01-10\", \"2018-03-20\"])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.info()\n",
    "print(\"DataFrame: \\n\",df.head())\n",
    "\n",
    "# Column Selection\n",
    "name_series = df[\"Name\"]\n",
    "print(\"Name Series:\\n\", name_series, \"\\n\")\n",
    "\n",
    "subset = df[[\"Name\", \"Salary\"]]\n",
    "print(\"Subset of DataFrame [Name and Salary:\\n\", subset, \"\\n\")\n",
    "\n",
    "# Row Selection by Position\n",
    "first_row = df.iloc[0] # First row (As a series)\n",
    "print(\"First row using iloc:\\n\", first_row, \"\\n\")\n",
    "\n",
    "# Row Selection by label (Our index is 0,1,2,3...)\n",
    "row_label_2 = df.loc[2]\n",
    "print(\"Row with index label 2 using loc:\\n\", row_label_2, \"\\n\")\n",
    "\n",
    "# Filtering (Boolean Indexing)\n",
    "\n",
    "high_salary = df[df[\"Salary\"] > 70000]\n",
    "print(\"Employees with Salary > 70000:\\n\", high_salary, \"\\n\")\n",
    "\n",
    "IT_employees = df[df[\"Dept\"] == \"IT\"]\n",
    "print(\"Employees in IT Dept:\\n\", IT_employees, \"\\n\")\n",
    "\n",
    "# Combined condition: IT and salary greater than 75000\n",
    "\n",
    "IT_high_salary_employees = df[(df[\"Dept\"] == \"IT\") & (df[\"Salary\"] > 75000)]\n",
    "print(\"IT employees with salary greater than 75000:\\n\", IT_high_salary_employees, \"\\n\")\n",
    "\n",
    "#Sorting\n",
    "sorting_by_salary = df.sort_values(\"Salary\", ascending=False)\n",
    "print(\"Employees sorted by Salary (desc):\\n\", sorting_by_salary,\"\\n\")\n",
    "\n",
    "# Visual Explanation of condition df for boolean\n",
    "print(df[\"Salary\"] > 800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c23980a-6606-4567-84a2-59c3a2235ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "\"Name\": [\"Alice \", \"Bob\", \"Charlie\", \"Eve\"],\n",
    "\"Age\": [25, 30, 35, 40 ],\n",
    "\"City\": [\"NY\", \"LA\", \"NY\", \"LA\", ],\n",
    "\"Score\": [85, 90, 88, 75]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad11fb-9373-4fff-a18c-4b043a05b0cf",
   "metadata": {},
   "source": [
    "Using the DataFrame df or a dataset of your own:\n",
    "1. Select only the \"Name\" column\n",
    "using two different methods (as a Series, and as a one-column DataFrame). (Hint: df[\"Name\"] vs\n",
    "df[[ \"Name\" ]] .) \n",
    "2. Select the first two rows of the DataFrame using .iloc . \n",
    "3. Select the last row\n",
    "using .iloc (you can use -1 as the index in Python for last). \n",
    "4. Filter the DataFrame to only include rows\n",
    "where Age is greater than 30.\n",
    "5. Filter to include rows where City is \"NY\" or \"LA\" (use the | operator\n",
    "for OR). \n",
    "6. Sort the DataFrame by Score in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "358f3433-9d52-402d-84fb-b795cfbbf1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name column as Series:\n",
      " 0     Alice \n",
      "1        Bob\n",
      "2    Charlie\n",
      "3        Eve\n",
      "Name: Name, dtype: object \n",
      "\n",
      "Name column as DataFrame:\n",
      "       Name\n",
      "0   Alice \n",
      "1      Bob\n",
      "2  Charlie\n",
      "3      Eve \n",
      "\n",
      "First two rows:\n",
      "      Name  Age City  Score\n",
      "0  Alice    25   NY     85\n",
      "1     Bob   30   LA     90 \n",
      "\n",
      "Last row:\n",
      " Name     Eve\n",
      "Age       40\n",
      "City      LA\n",
      "Score     75\n",
      "Name: 3, dtype: object \n",
      "\n",
      "Age > 30:\n",
      "       Name  Age City  Score\n",
      "2  Charlie   35   NY     88\n",
      "3      Eve   40   LA     75 \n",
      "\n",
      "City is NY or LA:\n",
      "       Name  Age City  Score\n",
      "0   Alice    25   NY     85\n",
      "1      Bob   30   LA     90\n",
      "2  Charlie   35   NY     88\n",
      "3      Eve   40   LA     75 \n",
      "\n",
      "Sorted by Score (descending):\n",
      "       Name  Age City  Score\n",
      "1      Bob   30   LA     90\n",
      "2  Charlie   35   NY     88\n",
      "0   Alice    25   NY     85\n",
      "3      Eve   40   LA     75 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "\"Name\": [\"Alice \", \"Bob\", \"Charlie\", \"Eve\"],\n",
    "\"Age\": [25, 30, 35, 40 ],\n",
    "\"City\": [\"NY\", \"LA\", \"NY\", \"LA\", ],\n",
    "\"Score\": [85, 90, 88, 75]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select only the \"Name\" column\n",
    "print(\"Name column as Series:\\n\", df[\"Name\"], \"\\n\")\n",
    "print(\"Name column as DataFrame:\\n\", df[[\"Name\"]], \"\\n\")\n",
    "\n",
    "# Select the first two rows\n",
    "print(\"First two rows:\\n\", df.iloc[0:2], \"\\n\")\n",
    "\n",
    "# Select the last row\n",
    "print(\"Last row:\\n\", df.iloc[-1], \"\\n\")\n",
    "\n",
    "# Filter where Age > 30\n",
    "print(\"Age > 30:\\n\", df[df[\"Age\"] > 30], \"\\n\")\n",
    "\n",
    "# Filter where City is NY or LA\n",
    "print(\"City is NY or LA:\\n\", df[(df[\"City\"] == \"NY\") | (df[\"City\"] == \"LA\")], \"\\n\")\n",
    "\n",
    "# Sort by Score descending\n",
    "print(\"Sorted by Score (descending):\\n\", df.sort_values(by=\"Score\", ascending=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298cb9cc-1627-4e0e-b289-45ed5e668f85",
   "metadata": {},
   "source": [
    "# Data Cleaning-Handling Missing Values and Data Types\n",
    "Real datasets are often messy: missing values, wrong types (e.g., numbers stored as strings),\n",
    "inconsistent formatting (caps, spaces), duplicates, etc).\n",
    "Pandas offers tools to clean and prep the data for analysis.\n",
    "\n",
    "Missing Values:\n",
    "Pandas uses NaN (Not a Number) or None as placeholders for missing data.\n",
    "Key Functions: df.isna() or df.isnull() - returns a DataFrame of booleans where True = missing\n",
    "- df.notna() - opposite. - df.isna().sum() - sum of True by columns gives count to NaNs in each column\n",
    "- Dropping missing - df.dropnna() - drops any row with NaN in any column (You can change with how = 'all'\n",
    "  to drop only if all columns are NaN, or axis = 1 to drop columns with NaNs.)\n",
    "- Filling missing: df.fillna(value) - replace NaNs with specified value (e.g., 0 or \"Unknown\").\n",
    "- We can also do df.fillna(method='ffil') to forward-fill (use last known value) or bfill for backward-fill\n",
    "  useful in time series\n",
    "- You can fill with different values per column by passing a dict\n",
    "  df.fillna({\"Age\":df[\"Age\"].mean(), \"City\": \"Unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02099190-d25d-4a39-a2f7-a8cf0dd7d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Score\n",
      "0  False  False\n",
      "1   True  False\n",
      "2  False   True\n",
      "Name     1\n",
      "Score    1\n",
      "dtype: int64\n",
      "      Name  Score\n",
      "0    Alice   95.0\n",
      "1  Unknown   85.0\n",
      "2  Charlie   90.0\n"
     ]
    }
   ],
   "source": [
    "df_miss = pd.DataFrame({\n",
    "    \"Name\": [\"Alice\", None, \"Charlie\"],\n",
    "    \"Score\": [95, 85, None]\n",
    "})\n",
    "print(df_miss.isna())\n",
    "print(df_miss.isna().sum()) # Count NaNs per column\n",
    "\n",
    "df_miss_filled = df_miss.fillna({\"Name\": \"Unknown\", \"Score\": df_miss[\"Score\"].mean()})\n",
    "print(df_miss_filled)\n",
    "# We replaced missing name with \"Unknown\" and missing Score with mean score.\n",
    "\n",
    "\n",
    "# Caution:\n",
    "# Filling numerical NaN with mean (as float) is fine; it was int column, it becomes float (Since NaN is float).\n",
    "# You can convert dtype later if needed (df[\"Score\"] = df[\"Score\"].astype['Int64'] for nullable int type\n",
    "# that can hold NaN.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5b769-7d15-4c3f-9859-04dfb0dabc03",
   "metadata": {},
   "source": [
    "# Data Type Conversions\n",
    "\n",
    "- Check df.dtypes to see types.\n",
    "  Common cleaning:\n",
    "- Number read as strings -> convert numeric with pd.to_numeric with pd.to_numeric(series, errors='coerce')\n",
    "  (will turn non-vertible to NaN) or series.astype(int/float) if you're sure all are numeric.\n",
    "- String that are actually dates -> pd.to_datetime(series, errors='coerce') to convert.\n",
    "- Categorical data (like entries repeating) -> you can convert to pandas \"category\" dtype to save memory or\n",
    "  to indicate it's categorical (e.g, df[\"City\"] = df[\"City\"].astype('category')).\n",
    "\n",
    "\n",
    "  Example: df_people[\"Age\"] = pd.to_numeric[df_people[\"Age\"], errors='raise')\n",
    "  If a non-numeric is found, errors='raise' would throw, errors='coerce' would set those to NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac8077-6b70-4c07-be25-e5f3f3ef2d6c",
   "metadata": {},
   "source": [
    "# String Operations\n",
    "\n",
    "Pandas Series have a .str accessor to apply string methods element-wise.\n",
    "\n",
    "- df[\"Name\"].str.lower()/upper()/title() - change case.\n",
    "- df[\"ID\"].str.strip() - remove any leading/trailling whitespace.\n",
    "- df[\"Email\"].str.contains(\"@gmail.com\") - Boolean Series if substring present.\n",
    "- df[\"City\"].str.replace(\"New York\", \"NYC\") - simple replacements (Can use regex too)\n",
    "- Categorical data (like entries repeating) -> you can convert to pandas \"category\" dtype to save memory or\n",
    "  to indicate it's categorical (e.g, df[\"City\"] = df[\"City\"].astype('category'))\n",
    "\n",
    "  Example: df_people[\"Age\"] = pd.to_numeric[df_people[\"Age\"], errors='raise')\n",
    "  If a non-numeric is found, errors='raise' would throw. errors='coerce' would  set those to NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742d76b-ff28-4b8c-83de-2264764d4b45",
   "metadata": {},
   "source": [
    "# Removing The Duplicates\n",
    "\n",
    "- df.duplicated() - Boolean series, True for rows that are duplicates of previous row (can specify subset of cols)\n",
    "- df.drop_duplicates() - removes duplicate rows (keeping the first occurance by default).\n",
    "  e.g, If we had duplicate entries in df_people, df_people.drop_duplicates(subset=[\"Name\"], keep=\"first\")\n",
    "  drop later enteries with same Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af1b3492-80c2-4723-a6d6-33bc9e2ea220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "     Name Age         City\n",
      "0  Alice  24     new york\n",
      "1    Bob  27  Los Angeles\n",
      "2    bob  27  los angelos\n",
      "3   None  45      Chicago\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.DataFrame({\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"bob\", None],\n",
    "    \"Age\": [\"24\", \"27\", \"27\", \"45\"],\n",
    "    \"City\": [\"new york\", \"Los Angeles\", \"los angelos\", \"Chicago\"]\n",
    "})\n",
    "print(\"Raw\\n\", df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a21ae3ea-69d6-475c-8992-e9b77bc93236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "# Strip and title-case Name and City\n",
    "df[\"Name\"] = df[\"Name\"].str.strip().str.title()\n",
    "df[\"City\"] = df[\"City\"].str.strip().str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ab9ee7d-62e0-4b0a-99b4-5a95d17a49dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned:\n",
      "       Name  Age         City\n",
      "0    Alice   24     New York\n",
      "1      Bob   27  Los Angeles\n",
      "3  Unknown   45      Chicago\n"
     ]
    }
   ],
   "source": [
    "# Handle Missing Name\n",
    "df[\"Name\"] = df[\"Name\"].fillna(\"Unknown\")\n",
    "\n",
    "# Convert Age to Numeric\n",
    "df[\"Age\"] = pd.to_numeric(df[\"Age\"], errors='coerce')\n",
    "\n",
    "# Drop the duplicates for Name (Keeping first)\n",
    "df = df.drop_duplicates(subset=\"Name\", keep='first')\n",
    "\n",
    "print(\"Cleaned:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583bc3a-a55c-4bf3-8d2d-2c175b8e4c45",
   "metadata": {},
   "source": [
    "# Feature Engineering - Creating New Columns\n",
    "Feature engineering involves transforming existing data or creating new features (columns that may\n",
    "be useful for analysis or modeling. The could be derived metrics, categorical encodings, flags.\n",
    "\n",
    "You can create new columns by assignment to df[\"NewCol\"]\n",
    "\n",
    "- df[\"TotalScore\"] = df[\"Score1\"] + df[\"Score2\"]\n",
    "- df[\"AvgScore\"] = df[[\"Score1\",\"Score2\"]].mean(axis=1)\n",
    "\n",
    "If you apply a scalar operation:\n",
    "- df[\"Score1_pct\"] = df[\"Score1\"] / df[\"Score\"1].sum() * 100\n",
    "\n",
    "Conditional columns\n",
    "- Using np.where or boolean logic:\n",
    "  For exampe, mark if a student passes both tests\n",
    "  - import numpy as np\n",
    "  - df[\"PassedBoth\"] = np.where(df[\"Score\"]>=60) & (df[\"Score2\"]>=60), True, False)\n",
    "- where()\n",
    "- df[\"HonorRoll\"] == df[\"AvgScore\"].where(df[\"AvgScore\"]>=90, other=8) # Keeps score if >90 else 8\n",
    "\n",
    "- You might also combine text\n",
    "  - df[\"fullName\"] = df[\"FirstName\"] + \" \" + df[\"lastName\"]\n",
    "- Extract part of a string\n",
    "  - df[\"Domain\"] = df[\"Email\"].str.split(\"@\", expand=True)[1]\n",
    "- Data example, if you have a datetime column\n",
    "  - df[\"Year\"] = df[\"Date\"].dt.year\n",
    "  - df[\"Month\"] = df[\"Date\"].dt.month.name()\n",
    "  - df[\"IsWeekend\"]  = df[\"Date\"].dt.weekday >= 5\n",
    "- Encoding the Categorical Varibles\n",
    "  - Mapping to numerics, e.g, df[\"GenderCode\"] = df[\"Gender\"].map(\"Male\":1, \"Female\":0)\n",
    "  - One-hot encoding: Turn categories into dummy/indicator columns\n",
    "    dummies = pd.get_dummies(df[\"Category\"], prefix=\"Cat\")\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    This will add columns Cat_A, Cat__B... with 1/0 indicating presence of category (useful for\n",
    "    machine learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73bb1b97-34ad-404a-8ef5-4a3030fa74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  BirthYear City  Age2025  IsNYC       NameCity\n",
      "0    Alice       1990  NYC       35      1    Alice (NYC)\n",
      "1      Bob       1985   LA       40      0       Bob (LA)\n",
      "2  Charlie       1992  NYC       33      1  Charlie (NYC)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"BirthYear\": [1990, 1985, 1992],\n",
    "    \"City\": [\"NYC\", \"LA\", \"NYC\"]\n",
    "})\n",
    "# Add current age in 2025\n",
    "df[\"Age2025\"] = 2025 - df[\"BirthYear\"]\n",
    "# Flag if from NYC\n",
    "df[\"IsNYC\"] = df[\"City\"].apply(lambda x: 1 if x==\"NYC\" else 0)\n",
    "# Combine name and City\n",
    "df[\"NameCity\"] = df[\"Name\"] + \" (\" + df[\"City\"] + \")\"\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e10c32-2cf9-4022-b986-100c340974e6",
   "metadata": {},
   "source": [
    "# GroupBy and Aggregation - Summerizing Data\n",
    "It is essential for analyzing data by catagories - similar to SOL's GROUPBY.\n",
    "It involves splitting data into groups, applying as aggregate function, and combining results.\n",
    "\n",
    "Common Aggregations: sum, mean, min, max, median, std, etc.\n",
    "\n",
    "- The GroupBy process.\n",
    "  - Split: Define groups based on one or more keys(columns). e.g, group by \"City\"\n",
    "  - Apply: Compute an aggreate for each group(sum of sale per city, average age per city, etc)\n",
    "  - Combine: The results are returned in a new Series or DataFrame indexed by the group Key(s)\n",
    "- Pandas Syntax.\n",
    "    - df.groupby(\"Column\")[\"OtherColumn\"].function()\n",
    "  Note: if you omit the [\"OtherColumn\"]. It will attempt to aggregate all numeric columns by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f91567c-7c09-4610-a967-c0f4af814d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      City  Revenue  Quantity\n",
      "0       NY      100        30\n",
      "1       LA       80        20\n",
      "2       NY       90        25\n",
      "3       LA       70        30\n",
      "4  Chicago       60        15\n"
     ]
    }
   ],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"City\": [\"NY\", \"LA\", \"NY\", \"LA\", \"Chicago\"],\n",
    "    \"Revenue\": [100, 80, 90, 70, 60],\n",
    "    \"Quantity\": [30, 20, 25, 30, 15]\n",
    "})\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104bf28c-2a07-4608-9805-621d3b8e976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Chicago     60\n",
      "LA         150\n",
      "NY         190\n",
      "Name: Revenue, dtype: int64\n",
      "Info of the groupby result <bound method Series.info of City\n",
      "Chicago     60\n",
      "LA         150\n",
      "NY         190\n",
      "Name: Revenue, dtype: int64>\n"
     ]
    }
   ],
   "source": [
    "# Group by City for the total revenue\n",
    "rev_by_city = sales.groupby(\"City\")[\"Revenue\"].sum()\n",
    "print(rev_by_city)\n",
    "\n",
    "print(\"Info of the groupby result\", rev_by_city.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79585083-0b9e-4d5d-ba4e-e0914bdf2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Revenue  Quantity\n",
      "City                      \n",
      "Chicago       60        15\n",
      "LA           150        50\n",
      "NY           190        55\n"
     ]
    }
   ],
   "source": [
    "# Multiple Aggregation: Sum of Revenue and Quantity by City\n",
    "agg_by_city = sales.groupby(\"City\").agg({\"Revenue\": \"sum\", \"Quantity\": \"sum\"})\n",
    "print(agg_by_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2a1139b-2e50-433e-a294-75319f5146be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding another category columna; \n",
      "       City  Revenue  Quantity Category\n",
      "0       NY      100        30        A\n",
      "1       LA       80        20        A\n",
      "2       NY       90        25        B\n",
      "3       LA       70        30        A\n",
      "4  Chicago       60        15        B\n",
      "After multi groupby \n",
      " City     Category\n",
      "Chicago  B            60\n",
      "LA       A           150\n",
      "NY       A           100\n",
      "         B            90\n",
      "Name: Revenue, dtype: int64\n",
      "\n",
      " Turned into df \n",
      "       City Category  Revenue\n",
      "0  Chicago        B       60\n",
      "1       LA        A      150\n",
      "2       NY        A      100\n",
      "3       NY        B       90\n"
     ]
    }
   ],
   "source": [
    "# You can also pass a list of functions\n",
    "sales.groupby(\"City\")[\"Revenue\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "# Here since City is a categorical datatype\n",
    "\n",
    "# For a single column group, you get Series output (as in rev_by_city).\n",
    "# If grouping by more than one key.\n",
    "\n",
    "# Example group by two keys (City and maybe another, but our data doesn't have\n",
    "# another category\n",
    "# Let's add a fake category column for demonstration\n",
    "\n",
    "sales[\"Category\"] = [\"A\", \"A\", \"B\", \"A\", \"B\"]\n",
    "print(\"After adding another category columna; \\n\", sales)\n",
    "multi_group = sales.groupby([\"City\", \"Category\"])[\"Revenue\"].sum()\n",
    "print(\"After multi groupby \\n\", multi_group)\n",
    "# This is a multi-index Series. You can .reset_index() to turn it to a Falt DF\n",
    "multi_group_df = multi_group.reset_index()\n",
    "print(\"\\n Turned into df \\n\", multi_group_df)\n",
    "\n",
    "# We can also iterate over df.groupby(\"City\")\n",
    "\n",
    "print('\\n results of sales.groupby(\"City\") \\n', sales.groupby(\"City\"))\n",
    "for city, group in sales.groupby(\"City\"):\n",
    "    # print(\"\\n\", group)\n",
    "    print(city, \"->\", group, len(group), \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ef5e1-ebb8-430f-bcaa-7a3c7bc33b7c",
   "metadata": {},
   "source": [
    "# Combining DataFrames - Merges and Join\n",
    "- Use pd.merge(df1, df3, how='inner', on='KeyColumn')\n",
    "- Alternatively df1.merge(df2, how='left', left_on='key1' right_on=\"key2\")\n",
    "\n",
    "  - Join types:\n",
    "  - Inner join: only matchinng keys in both(default)\n",
    "  - Left join: all keys from left, add data from right when keys match\n",
    "    (unmatched get NaN or right cals)\n",
    "  - Right join: opposite of left.\n",
    "  - Outer join: all keys from both, NaN where no match on either side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e5fb9f9-a10a-4d8a-8145-e6fde751cfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers:\n",
      "    CustomerID     Name\n",
      "0           1    Alice\n",
      "1           2      Bob\n",
      "2           3  Charlie\n",
      "Orders:\n",
      "    OrderID  CustomerID  Amount\n",
      "0      101           2     250\n",
      "1      102           2     100\n",
      "2      103           3      50\n",
      "3      104           4     300\n"
     ]
    }
   ],
   "source": [
    "df_customers = pd.DataFrame({\n",
    "    \"CustomerID\": [1, 2, 3],\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "})\n",
    "df_orders = pd.DataFrame({\n",
    "    \"OrderID\": [101, 102, 103, 104],\n",
    "    \"CustomerID\": [2, 2, 3, 4],\n",
    "    \"Amount\": [250, 100, 50, 300]\n",
    "})\n",
    "\n",
    "print(\"Customers:\\n\", df_customers)\n",
    "print(\"Orders:\\n\", df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d75a0a7-bd32-4ffc-b4c7-79e593a66d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner join on CustomerID:\n",
      "    CustomerID     Name  OrderID  Amount\n",
      "0           2      Bob      101     250\n",
      "1           2      Bob      102     100\n",
      "2           3  Charlie      103      50\n"
     ]
    }
   ],
   "source": [
    "# Merge customers with orders on CustomerID:\n",
    "merged = pd.merge(df_customers, df_orders, how='inner', on=\"CustomerID\")\n",
    "print(\"Inner join on CustomerID:\\n\", merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc40289-e284-4320-bd82-2ff23697e6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
